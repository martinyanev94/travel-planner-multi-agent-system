import nltk
from nltk.tokenize import word_tokenize

# Sample text
text = "Hello, World! Welcome to NLP. Let's tokenize this text."

# Tokenizing the text
tokens = word_tokenize(text)
print(tokens)
